# ğŸ‡¬ğŸ‡§ English Interview Practice Script
 
#### Introduction 
Okay, letâ€™s start!  
Here I'm known as Cartaxo. You can call me Cartaxo.
when you donâ€™t practice, you forget a few things.
One of my _main goals_ is _to work on_ an international project â€” to keep improving my English skills.
I can handle most work situations in English â€” reading, understanding business rules, and discussing technical topics.
Back in 2023, I went to Europe â€” one of my goals was to practice my English.
I went to Europe and visited some countries.
i visited London.
That same year, I also had the opportunity to be part of a team that included some English colleagues.
In that project, I was involved in several business decisions, mainly because I was the Tech Lead

--- 

#### Personal Life
Hi, my name is Carlos. 
Iâ€™m 47 years old, married, and i have two daughters.  
I live in ItajaÃ­, Its a coastal city in southern Brazil.  
In my free time, I love going to the beach, exploring new places, and spending time with my family.  
Cycling is my favorite sport â€” itâ€™s how I stay active and recharge my batteries

--- 

#### Academic Background
I graduated in Information Systems, and later I completed two postgrad courses in IT â€” one in Software Engineering and 
another focused on Java for Web development.

---

#### Falar um pouquinho sobre outras atividades como sou dev, teach lead e arquiteto de software
Iâ€™ve had experience as a developer, tech lead, and architect, and I really enjoy all three roles.

- As a developer:
  I like being hands-on â€” coding in Java and Kotlin,
  solving problems, and
  making services faster and more reliable.
  Besides development, I also take care of the delivery side â€” adjusting pipelines in Jenkins, improving CI/CD steps,
  managing deployments, and configuring Kubernetes.
  I spend a good amount of time looking at logs, traces, dashboards, and overall observability to keep the systems healthy and reliable.

- As a tech lead, I enjoy helping the team, unblocking people, and making sure weâ€™re aligned on good practices and clean design.

- as an architect, I focus on the bigger picture â€”
  building scalable, resilient solutions and making decisions that keep the system healthy over time.

What I like the most is being flexible. If the team needs me coding, I code. If they need guidance, I jump in and support.
If they need someone thinking about architecture and trade-offs, Iâ€™m comfortable doing that too.
I like working in a collaborative environment, helping people grow, and making sure we deliver something solid together.

---

## Pagseguro
I currently work at PagSeguro, in the Account Security domain. 
My team is responsible for the first layer of user authentication. 
We handle password matching, password recovery, and that is our main scope.

backend
We maintain nine microservices that support others internal services across PagSeguro.
We work mainly with Kotlin â€” itâ€™s our primary language â€” although, in general, other squads at PagSeguro still use Java.
Regarding the code within my team, I also perform code reviews and help with other improvements in the codebase.
My daily work involves new features, performance improvements, and refactoring.

CI
I also take care of the deployment pipelines â€” specifically the Jenkins pipelines used for our deployments.

We operate in a multi-cloud environment, running deployments in Kubernetes as well as in AWS. 
Iâ€™m also responsible for production deployments. 
Another part of my role is investigating customer access issues in production by analyzing logs in Splunk and other internal data sources, 
    and providing support to the customer service team when necessary.

â€œIâ€™m responsible for deploying and maintaining our microservices running on Kubernetes. 
I work with deployment manifests, services, ingresses, autoscaling rules, 
and the overall configuration required for running applications in the cluster.â€
ğŸ“Œ Se quiser uma versÃ£o ainda mais elegante:
â€œI manage the entire lifecycle of our Kubernetes deployments â€” writing and adjusting manifests, 
configuring services and ingresses, handling autoscaling, and ensuring that the workloads run properly in the cluster.â€

e sobre aws?
Regarding AWS, we are in the process of decommissioning our services there, 
since the company is moving toward using only our own private infrastructure. 
But yes, we still have a few workloads deployed in AWS at the moment. 
We also maintain some TFVars files that contain provisioning and resource configuration for AWS.

Aside ECS â€” AWS Elastic Container Service â€” which is still active, 
    we are shutting down all the remaining AWS components. 
We donâ€™t use CloudWatch logs, we donâ€™t use AWS monitoring, and we donâ€™t rely on any messaging brokers 
    or managed services there. 
ECS is the only service still running in AWS, and even that is being phased out.

Another responsibility I have within the team is monitoring our alerts. 
We have several alerts configured in Grafana, and the main ones include Rate Limit, Throughput, Latency, and Error Rate. 
I handle these alerts daily, reviewing dashboards and investigating any spikes or anomalies to prevent customer-impacting issues.

others technologies envolved
Across our microservices, we handle both synchronous communication, 
    using standard REST, 
    and asynchronous communication using Kafka...
both for internal microservice interactions and for sending data to BI systems.

---

#### Em que situacoes falou em ingles para trabalho?
Two years ago, I worked as a Tech Lead in a squad, 
and since we had a mobile development team, we often made presentations to the projectâ€™s CEO. 
She was English, so we presented the features we developed in English. It was a garage logistics implementation.

In another situation, when I worked in the financial area, 
I sometimes supported clients who had issues with their card machines. 
To assist them, I spoke with a few support agents who were Indian and communicated in English.

#### Relevant Projects 

available, scalable, performant, and resilient
1. Available
   The system should be up and running when users need it.
   High availability minimizes downtime and ensures the application remains accessible even during failures,
   maintenance, or traffic peaks.

2. Scalable
   The application must be able to handle growth smoothly â€” more users, more requests, more data.
   Scalability means the system can expand horizontally or vertically without degrading the experience.

3. Performant
   The system should respond quickly and efficiently.
   High performance means low latency, optimized resource usage, and fast execution of critical operations, even under load.

4. Resilient
   The application must be prepared to survive failures.
   Resilience includes fault tolerance, retries, timeouts, circuit breakers, and graceful degradation so the system
   continues operating even when parts of it fail.
--- 

#### Challenges Faced
I believe the architecture is not the problem,
and engineering is not the problem either.
Of course, each one has its own complexity,
but what really makes a project difficult is the business rules.

Some projects demand a deep understanding of the business itself â€”
much more than implementation or the technical side.
And thatâ€™s always a challenge.

--- 

#### Thanking the Interviewer
---    

#### How Do You See Yourself in 5 Years?
    I donâ€™t worry much about that. 
    I just try to keep up with new tech and software architecture trends. 
    But one of my goals is definitely to work with people from different countries. to improve my communication skills

---

#### Strengths and Weaknesses 
#### Technical Challenge Example
All the major challenges Iâ€™ve faced in IT were related to transforming a monolith into microservices. 
The real complexity in that process is keeping the transactions consistent. 
--- 

#### problemas ao entender
â€œSorry, could you please repeat that?
My English is a bit rusty â€” I havenâ€™t practiced as much lately.
But Iâ€™m following youâ€
--- 

[START]

#### [TAG Scrum & Agile]
How familiar are you with Agile methodologies, such as Scrum?  

Agile in a squad means working in short cycle.
We move forward together and hand in hand as a squad
adjusting the course as the team moves forward.

we have daily stand-ups, 
sprint planning,
Grooming sessions
reviews, 
and retrospectives.

Grooming sessions are basically meetings where the team reviews and refines the backlog. 
We clarify the business rules, 
break big stories into smaller ones, 
discuss edge cases, 
check dependencies, 
and make sure everything is clear before development starts.

    â€œWe covered all the Kafka requirements during the grooming session.â€
    â€œLetâ€™s schedule a grooming session to refine the new Spring flow.â€
    â€œDuring grooming we found missing acceptance criteria.â€
    â€œThe story looked simple, but once we started grooming we identified some technical challenges.â€

#### [TAG Backend & Architecture] HIGH LEVEL
# Arquitetura de Software (nÃ­vel macro, decisÃµes estruturais)

when we talk about software architecture, we can divide it into three main areas:
### 1 - Distribution Styles, 
### 2 - Internal Organization Styles 
### 3 - Integration Styles
### 4 - Execution Models (onde/como rodam)

### 1 - Distribution Styles (how I divide the system into applications/services)
Monolith (or Modular Monolith)     mÃ³nolif
Pros and cons: simple to develop, test, and deploy; difficult to scale and maintain as it grows.

SOA (Service-Oriented Architecture): larger services sharing contracts; usually more tightly coupled than microservices.
Pros and cons: simplifies integration with legacy systems; can lead to bottlenecks and complexity with an ESB.

Microservices: small, independent services aligned with bounded contexts (DDD).
Note: bounded contexts are parts of the domain that have their own language and model, 
and can be implemented as separate microservices.
Pros and cons: improves scalability and maintainability; more complex to develop, test, and deploy.

Serverless: functions or containers managed by a cloud provider, paying only for usage.
Pros and cons: reduces infrastructure overhead; may have execution limits and vendor lock-in.

> ### 2 - Internal Organization Styles (how I structure each application, whether monolith or microservice)
Layered Architecture: presentation â†’ domain â†’ infrastructure/data.
Clean Architecture structures software into concentric layers, ensuring that business rules remain independent of frameworks, 
    databases, and the user interface.
Hexagonal Architecture â€” also known as Ports and Adapters â€” 
    takes a more pragmatic approach, emphasizing clear separation between contracts (ports) and their implementations (adapters).
Both architectures share the same core principle: keeping business logic at the heart of the system, while pushing technical details to the outer layers.

### 3 - Integration Styles (how parts communicate)
Synchronous via API:
REST, gRPC, GraphQL (API-Driven).
â†’ gRPC is a remote communication framework developed by Google that uses HTTP/2 for transport and Protobuf for data serialization.
â†’ Protobuf (Protocol Buffers) is an efficient and compact data serialization format used to define the structure of messages exchanged between services.

Asynchronous via Messaging / Event-Driven:
Kafka, RabbitMQ, SNS/SQS (pub/sub, event-carried state transfer, CQRS + Event Sourcing as optional patterns).

### 4 - Execution / Deployment Models
Containers & OrquestraÃ§Ã£o: Docker + Kubernetes (microservices ou monÃ³litos containerizados). 

#### [TAG Backend & Architecture] LOW LEVEL
Itâ€™s a set of engineering practices that support the architecture by keeping components cohesive, decoupled, and easy to evolve
aqui entra: solid etc

#### [TAG Design & Development Practices]
## Applying development techniques
code quality ia a set of practices that need to work together in harmony.
 
This includes: 
- clean code principles, 
- SOLID, 
- design patterns, 
- test-driven development when appropriate, 
- continuous integration, 
- refactoring, 
- and documentation.
These techniques minimize technical debt, reduce coupling, and help the architecture remain consistent and scalable.

@clean code principles
Meaningful Names
Small, Focused Functions
Single Responsibility Principle (SRP)
Avoid Duplication (Donâ€™t Repeat Yourself) e KISS (Keep It Simple, Stupid) - evite duplicaÃ§Ã£o e complexidade desnecessÃ¡ria
Clear Error Handling (good: throw new CustomerNotFoundException(id); bad:return null;)

@SOLID
S -> Single Responsibility Principle (SRP) [Each class must have a single responsibility]
O -> Open/Closed Principle (OCP) [Classes must be open for extension, but closed for modification]
L -> Liskov Substitution Principle (LSP) [Subtypes must be able to replace their base types without breaking the program]
I -> Interface Segregation Principle (ISP) [Interfaces must be small and specific]
D -> Dependency Inversion Principle (DIP) [Rely on abstractions, not implementations] 

@YAGNI (You Arenâ€™t Gonna Need It) - nÃ£o implemente algo que nÃ£o Ã© necessÃ¡rio agora
I also value peer code reviews, static analysis tools like SonarQube, and a solid base of unit tests to maintain a consistent and high-quality codebase.

## Applying engineering techniques
I apply Domain-Driven Design (DDD) to keep business logic organized and modular.
I use TDD when it makes sense, because it helps produce more reliable code with less rework.
In some cases, I use BDD to ensure the system reflects the expected behavior from the user or business perspective.

## In the code workflow and versioning 
Before any merge, we always perform a code review.
We use semantic commits to keep the Git history clean and easy to trace.
And we follow good versioning and workflow practices using Git and GitHub (or GitLab, depending on the project).

@Design patterns
â€œThe three main categories are creational, structural, and behavioral. 
For example, Singleton, Factory Method, and Builder are creational patterns that focus on object creationâ€¦â€
1**Creational Patterns**
Singleton
Ensures there is only one instance of a class and provides a global point of access to it.
Example: an application-wide ConfigurationManager.

Factory Method
Defines an interface for creating objects, but lets subclasses decide which concrete class to instantiate.
Example: creating different types of PaymentProcessor depending on the payment method.

Builder
Separates the construction of a complex object from its representation, allowing you to build the object step by step.
Example: building an Order object with many optional fields.

**Structural Patterns**
Adapter
Converts the interface of a class into another interface that clients expect.
Example: adapting an external API to match the internal model of your application.

Decorator
Adds extra behavior to an object dynamically, without changing the original class.
Example: adding logging, metrics, or caching around a Service.

Facade
Provides a simple interface to a complex subsystem or set of classes.
Example: a PaymentFacade that orchestrates fraud check, charging, and notification.

**Behavioral Patterns**
Strategy
Defines a family of algorithms and makes them interchangeable at runtime.
Example: different strategies to calculate shipping cost or discounts.

Observer
Defines a one-to-many dependency, where multiple objects are notified automatically when another objectâ€™s state changes.
Example: publishing events to listeners when an order is approved.

Chain of Responsibility
Lets you pass a request along a chain of handlers, where each handler decides whether to process the request or pass it to the next one.
Example: a validation pipeline for a request or business rules.
If you want, next I can turn this into a spoken answer like:

---

#### [TAG Security & Communication] 
> We use OAuth2 and JWT tokens for authentication and authorization.
<br> Encryption protects sensitive data in transit and at rest.
<br> gRPC and Protobuf improve performance for inter-service communication.
<br> Every request is logged for tracing and metrics.
<br> Logging, metrics, and tracing are the pillars of observability.
<br> We use Grafana and Prometheus for dashboards and alerting.
<br> OpenTelemetry standardizes our monitoring data.
<br> Splunk and Jaeger help analyze logs and distributed traces.
<br> Circuit breakers prevent cascading failures in distributed systems.
<br> We rely on load testing to assess system performance.

#### [TAG SPRING]
â€œSpring Boot accelerates backend development in Java. 
It lets us write less code, deal with fewer configuration files, and quickly spin up a new application. 
And thanks to the starters, everything becomes much simpler â€” dependencies, auto-configurations, and common setups basically work out of the box.â€

ğŸ”µ Spring Core
â€œItâ€™s like a box of LEGO pieces: everything is there, but you have to assemble the structure yourself.â€
It provides the essentials: IoC, Dependency Injection, ApplicationContext, AOP, and the foundation for Spring MVC and the entire Spring ecosystem. 

ğŸŸ¢ Spring Boot 
Itâ€™s like pre-assembled LEGO: most of the heavy lifting is already done. 
It reduces boilerplate and loads automatic configurations based on the dependencies you add. 

ğŸŸ£ Spring Starters
â€œItâ€™s like getting pre-assembled LEGO modules: most of the heavy lifting is already done for you.â€
It reduces boilerplate, handles configuration automatically, and boots your application using auto-configuration and 
opinionated defaults based on the dependencies you add.


1. Inversion of Control (IoC)
It is the principle where Spring itself controls the lifecycle of objects.
Instead of manually creating instances using new, Spring creates, manages, and provides these objects for you.

2. Dependency Injection (DI)
This is the mechanism Spring uses to apply IoC.
DI automatically injects dependencies into classes (via @Autowired, constructors, etc.).
This reduces coupling and makes the code cleaner, more modular, and easier to test.

3. Spring Container
This is the core of the Spring framework.
The Container is responsible for:
creating objects (beans)
managing their lifecycle
resolving dependencies
applying configurations
Nothing works without the Spring Container.

4. Spring MVC
This is the Spring module used to build REST APIs and web applications following the Modelâ€“Viewâ€“Controller pattern.
It provides:
routing (@Controller, @RestController)
HTTP request handling
JSON serialization
validation mechanisms

5. Spring Data Access (ORM)
This module simplifies data access.
It includes Spring Data JPA, integration with Hibernate, and other ORM technologies.
It greatly reduces boilerplate and automatically generates repository implementations.

6. Simplified Configuration
Spring offers multiple ways to configure an application in a simple and intuitive manner:
annotations (@Component, @Configuration, etc.)
YAML/Properties files
Spring Boot autoconfiguration
This removes the need for the large XML configuration files used in older versions.

7. Real-Time Capabilities
Spring provides support for reactive and real-time applications through:
Spring WebFlux
Streams
Backpressure
Reactive programming
This enables systems to handle thousands of simultaneous connections while consuming minimal resources.

ğŸ’¬ Professional Summary of My Experience with Spring <br>
I work with the full Spring ecosystem. <br>
In Spring Core, I use modules such as spring-core, spring-context, spring-aop, and spring-webmvc, 
which provide IoC, DI, and the foundation of the MVC model. <br>
With Spring Boot, I rely on starters like Web, Data JPA, Security, and Actuator to simplify configuration. <br>
I understand that starters are dependency bundles that automatically configure Spring Core modules. <br>
I also work with Spring Cloud to build microservices with distributed configuration, service discovery, 
resilience, and scalable communication. <br>

ğŸ“¦ Main Spring Stacks I Work With

ğŸŒ Web / REST <br>
spring-boot-starter-web (Spring MVC) <br>
spring-boot-starter-webflux (Reactive) <br>
spring-boot-starter-validation (Jakarta Validation) <br>
jackson-databind (JSON) <br>

ğŸ›¢ï¸ Persistence & Data <br>
spring-boot-starter-data-jpa (Hibernate) <br>
spring-boot-starter-data-mongodb <br>
spring-boot-starter-data-redis (cache / pub-sub) <br>
spring-boot-starter-jdbc <br>
flyway-core / liquibase-core (migrations) <br>

ğŸ” Security <br>
spring-boot-starter-security <br>
spring-security-oauth2-client / resource-server

ğŸ“¡ Messaging <br>
spring-kafka <br>
spring-retry, resilience4j-* <br>
spring-amqp (RabbitMQ) <br>

â˜ï¸ Integration / Cloud <br>
spring-cloud-openfeign (typed HTTP clients) <br>
spring-cloud-starter-config <br>
eureka-client / consul-discovery <br>
spring-cloud-starter-gateway (API Gateway / BFF)

ğŸ“Š Observability <br>
spring-boot-starter-actuator <br>
micrometer-registry-* <br>
opentelemetry-exporter-otlp (or auto-instrumentation)

ğŸ“„ Documentation <br>
springdoc-openapi-starter-webmvc-ui (Swagger UI)

â±ï¸ Jobs, Batch & Scheduling <br>
spring-boot-starter-batch <br>
@EnableScheduling with Spring Boot

ğŸ§ª Testing <br>
spring-boot-starter-test <br>
mockito-core <br>
wiremock-jre8 <br>
testcontainers

ğŸ› ï¸ Quality & Utilities <br>
mapstruct (mapping) <br>
lombok (boilerplate reduction) <br>
hibernate-validator
> 
---
## [TAG JAVA] 
> Build & Dependency Management (Maven, Gradle) 
**Q:** Which build tools do you use?  
**A:** Iâ€™ve used both Maven and Gradle. At PagSeguro, most Kotlin projects use Gradle because itâ€™s faster and easier to configure. For older Java projects, I still maintain Maven builds. I like keeping dependencies well-managed and versioned.

> Programming Languages (Java, Kotlin) 
**Q:** Which language do you prefer, Java or Kotlin?  
**A:** Iâ€™m comfortable with both, but Kotlin is my favorite for backend development â€” itâ€™s concise, expressive, and reduces boilerplate code. Still, I appreciate Javaâ€™s stability and ecosystem. I switch between them easily depending on the project.

versoes de kotlin que ja trabalhei?

versoes de spring que ja trabalhei?

---
#### [TAG TESTING] Understanding Testing in Backend Development
When we talk about testing, we can actually be referring to several different types of tests within backend development.

We might be talking about unit tests, where we test individual components or functions in isolation. These tests make sure that each small part of the system works as expected.
In Java, for example, we often use frameworks like JUnit and Mockito to create and execute unit tests. JUnit provides the structure for writing the tests, while Mockito helps us mock dependencies, simulating external behavior without needing to connect to real services or databases.

We can also be referring to integration tests. Unlike unit tests, these validate how different parts of the system work together â€” for example, how a service interacts with a database, or how two microservices communicate through an API. Integration testing ensures that the system behaves correctly as a whole.

Another important type is stress testing (or load testing). These tests check how the system behaves under heavy load â€” for instance, when thousands of users try to access the same resource at the same time. Stress tests are essential to verify scalability, performance, and resilience, ensuring the system can handle real-world traffic without failures.

We can also talk about mocked tests or simulated tests, often implemented with tools like WireMock. This approach is useful when we want to test interactions with external systems or APIs that are not available or are expensive to call in real time. WireMock lets us create fake endpoints that return predefined responses, allowing consistent and repeatable testing scenarios.

In summary, testing in backend development is not just about checking if the code works â€” itâ€™s about ensuring reliability, maintainability, and confidence in the software.
A good testing strategy usually combines multiple levels of testing â€” unit, integration, system, and performance â€” to cover the system from the smallest function to the most complex real-world scenario.
--- 
>
#### [TAG CI/CD] jenkis etc
about
**Q:** How do you handle CI/CD in your team?  
**A:** We use Jenkins for our CI/CD pipelines. Every commit triggers automatic builds, tests, and deployments.
We follow a multistage pipeline approach â€” from QA to production â€” ensuring every change passes all validations before going live.
CI and CD are ways to deliver code automatically.
there are some tools available.
Right now, I work with Jenkins. Iâ€™ve also used Jenkins in other companies before.
But there are other options, like Bitbucket, GitHub Actions, and Azure Pipelines. all of them are good options. 
 
Continuous Integration (CI) ensures that code changes are automatically tested.
Continuous Deployment (CD) automates the release of new features.
DevOps bridges the gap between development and operations.
Observability helps us understand the systemâ€™s behavior in production.
Scalability means the system can handle increasing traffic.
Resilience ensures recovery from failures.
Load balancing distributes traffic evenly among servers.
Fault tolerance allows the system to keep working even if one part fails.
Infrastructure as Code (IaC) lets us manage servers using versioned scripts.
We use a service mesh to handle communication between microservices.
>
## [TAG CLOUD]  
> Cloud Computing (AWS, GCP, Azure)
**Q:** Whatâ€™s your experience with cloud environments?  
**A:** I mainly work with AWS, using services like S3, SQS, and ECR for our deployments. But we also operate in a private cloud called PagCloud, which makes us a multicloud environment. I like this setup because it gives flexibility and resilience.
>
## [TAG KUBERNETES]  
> Containerization & Orchestration (Docker, Kubernetes) 
**Q:** Do you have experience with Docker or Kubernetes?  
**A:** Yes, I use Docker for building and packaging our applications, and we deploy everything on Kubernetes. I usually define deployments, services, and ingress configurations in YAML. Iâ€™ve also worked with blue-green and rollout deployment strategies.
>

[END]
--------------------------------------------------------------------------

## [TAG INVILLIA] 
1. If you had to choose between RabbitMQ and Kafka for a new system, what criteria would you consider?<br>
Which scenarios favor each technology and why? <br>
Also explain the main differences between queues and topics in messaging systems.<br>

When I need to choose between RabbitMQ and Kafka, I first: <br>
- look at the type of communication the system needs 
- and the message volume. 
- I also consider whether the team needs to reprocess events, what the expected latency is, 
and how the consumers are supposed to work.

**RabbitMQ** is great when the system follows a more â€œdo this nowâ€ style â€” tasks and commands. 
- It delivers fast, supports message-level ACKs, and offers flexible routing. 
- It works really well when each message needs to go to a single consumer, and the overall volume isnâ€™t extreme.

**Kafka** shines in high-volume scenarios, especially when the system is event-driven and needs to store messages for longer. 
- It allows multiple consumers to read the same event, keeps ordering within partitions, and makes reprocessing very easy. 
- Thatâ€™s usually my choice for more complex asynchronous integrations or event-driven observability.

The main difference between a queue and a topic is simple:
- A queue sends each message to one consumer â€” itâ€™s work distribution.
- A topic lets multiple consumers read the same message â€” itâ€™s event broadcasting.

---
> 
> 2. Como vocÃª utilizaria os serviÃ§os AWS (SNS, SQS, S3) para criar uma arquitetura escalÃ¡vel e tolerante a falhas?
> 
> When I build a scalable and fault-tolerant architecture using SNS, SQS, and S3, 
> I usually think of the whole thing as a loose, async pipeline.
> 
> SNS is my event distributor. It lets me notify multiple services at the same time, 
> which already boosts scalability a lot. 
> Itâ€™s great when different parts of the system need to react to the same event.
> 
> SQS works as the reliable buffer in the middle. 
> It makes sure no messages get lost, even if a consumer goes down. It also helps handle traffic spikes, 
> because you can scale consumers horizontally as the queue grows.
> 
> S3 is the durable storage for files, logs, or bigger payloads. 
> In many cases, I prefer sending only a â€œreferenceâ€ through SNS/SQS and keeping the heavy content in S3. 
> That reduces traffic, speeds things up, and makes consumption easier.
> 
> Overall, Iâ€™d use SNS â†’ SQS for a resilient fan-out pattern, and S3 as the central storage for static or large data. 
> This combo gives you a very decoupled architecture, easy to scale, and still works even if one component has issues.
> 
> ---
> 
3. What metrics do you consider essential to monitor in a microservices environment?<br>
   How would you implement observability?<br>
   What tools have you worked with before?

To monitor microservices, I track four essential categories of metrics:
- Infrastructure metrics: CPU, memory, GC activity, thread usage, and container limits.
- Application metrics: p95/p99 latency, error rates, throughput, dependency latency (database, Kafka, REST), 
  and connection-pool behavior.
- Messaging metrics: Kafka consumer lag, queue size, production/consumption rate, DLQ volume, and retries.
- Business metrics: processed orders/events, conversion rates, rule rejections, and end-to-end processing time.

These metrics allow me to monitor not only whether the service is â€œrunning,â€ but whether the business flow is actually healthy.

For observability, I implement the full triad:
- Structured logs with traceId, spanId, correlationId, and consistent JSON formatting.
- Metrics using Micrometer exporting to Prometheus, visualized in Grafana (or equivalent).
- Distributed tracing with OpenTelemetry to follow the entire lifecycle of a request across services.

Iâ€™ve worked with ELK, Splunk, New Relic, Datadog, CloudWatch, and Pagmon, as well as Kafka and RabbitMQ 
dashboards for analyzing lag, offsets, and consumer behavior.

This combination gives me the ability to detect bottlenecks, understand business impact, and react quickly during incidents.
 
4. In a distributed system where two microservices communicate via Kafka, how would you structure that communication?

When we implement asynchronous communication to solve a problem, we can easily introduce new problems if we're not careful. <br>
So before designing anything with Kafka, I first think about the risks I want to avoid.<br>
I need to predict some risks I want to avoid<br>
And what would be the main problems I want to prevent when two microservices communicate through Kafka?

Message loss or duplication
- A producer may send the event, but the consumer might not process it â€” or process it twice.

Event ordering
- Some scenarios must keep the order per entity, like all events for the same customerId or orderId.

Idempotency and reprocessing
- If I need to reprocess a topic or Kafka redelivers the same message, the consumer canâ€™t break the system state.

Contract coupling
- If the payload schema changes, I canâ€™t afford to break every consumer.<br>
Thatâ€™s why event versioning is important.

Backpressure / speed mismatch
- Producers can publish much faster than consumers can handle.

Error handling
- What do I do with messages that always fail? I need a proper retry strategy and a DLQ.

Observability
- I need to answer: What happened to this event? Did it fail? Who consumed it? Where did it stop?

Security and isolation
- Controlling who can publish and consume each topic.

If I ignore these points, the architecture might work fine in the happy path, but it will become 
a real source of pain in production.

Second: How I would structure the communication between the two microservices using Kafka

To minimize these risks, Iâ€™d structure the solution like this:
- Define clear domain events and contracts<br>
- No generic payloads. Iâ€™d use explicit events like CustomerCreatedEvent, OrderApprovedEvent, etc.<br>
And Iâ€™d use JSON or Avro with a well-defined, versioned schema.
- Topic modeling and keying strategy<br>
Iâ€™d create domain-oriented topics such as: customer-events or orders-events.<br>
And Iâ€™d use the entity ID (customerId, orderId) as the message key to maintain partition ordering.

- Add important metadata to each event
Things like: eventId (UUID), eventType, correlationId, sourceService, timestamp<br>
This helps with tracking, debugging, and idempotency.

Resilient producer<br>
Service A publishes to the topic with:
- Proper acks
- Retry with backoff
- And for critical cases, Iâ€™d use the Outbox pattern so the event is only published after the local transaction succeeds.

Idempotent consumer
- Service B consumes in a consumer group, allowing horizontal scaling.
- Processing must be idempotent: Use eventId or a referenceId and Keep a record of processed events 
to avoid duplicating effects

Structured retry and DLQ
- If processing fails due to a temporary issue:
- Send it to a retry topic with backoff (e.g., orders-events.retry)
- If it fails permanently (bad payload, rule violation):
- Move it to a DLQ (e.g., orders-events.dlq) for manual or specific processing.

Observability
Track metrics like:
- Consumer lag
- Error rate
- Consumption/production rate
- And log with correlationId and eventId, ideally using distributed tracing to connect HTTP requests â†’ Kafka events â†’ consumers.

Security and governance
- Use Kafka ACLs to define who can publish/consume.
- Follow a clear naming convention for topics to simplify governance.
---

5. Explique como vocÃª projetaria um banco de dados para um sistema de alta escala. Quando optaria por SQL vs NoSQL?

When I design a database for a high-scale system, I donâ€™t start with â€œSQL vs NoSQL.â€ I start with the requirements.

First, I look at the data model and the domain â€” how the entities relate, whether the structure is complex or 
more aggregate-based.

Then I consider the access patterns â€” is the system read-heavy or write-heavy, do we query mostly by ID, 
or do we need filters, reports, and joins?

I also check the non-functional requirements â€” data volume, expected latency, availability, and the level of 
consistency the business needs.

For high scale, I focus on a few pillars:<br>
- a data model aligned to the use cases,
- well-planned indexing and partitioning,
- and replication plus caching (like Redis) to offload the database during traffic spikes.

The idea is that scalability comes from the model + access patterns + infrastructure â€” not just from picking SQL or NoSQL.

When would I choose SQL?<br> 
- SQL is my choice when I need strong consistency, ACID transactions, and the domain has rich relationships 
and complex rules â€” things like financial flows, orders, limits, or anything that depends heavily on integrity and joins.

In short: when the business needs highly consistent, well-related data, SQL is usually the right fit.

When would I choose NoSQL? <br>
- Iâ€™d pick NoSQL when Iâ€™m dealing with massive data volume and need easier horizontal scaling.
- It fits well when the model is aggregate/document-oriented, when I need flexible schema evolution, 
and when the system can tolerate eventual consistency in exchange for low latency and high availability.

In short: when the focus is large scale, flexible schema, and simple access patterns, NoSQL is a strong choice.

---
>
> 6. Imagine que vocÃª estÃ¡ liderando uma equipe DevOps em um projeto crÃ­tico com 
> mÃºltiplos desenvolvedores trabalhando simultaneamente. 
> Como vocÃª utilizaria Git-Flow para gerenciar releases, hotfixes e branches de desenvolvimento, 
> garantindo integraÃ§Ã£o contÃ­nua e minimizando conflitos? 
> Quais prÃ¡ticas avanÃ§adas vocÃª recomendaria para otimizar esse fluxo?

> 7. Which features introduced in Java 16 or later have you already used, such as records, 
> sealed classes, or improvements to Pattern Matching? <br>
> Explain how these features work and in which scenarios you consider them advantageous.
> 
> I started back in the Java 7 days, working with JSF, managed beans, and the typical monolithic architecture 
> approach of that time. As Java evolved, I evolved with it.
> - Java 8 was a big turning point for me â€” especially with streams, lambdas, and the functional style 
> that changed the way we write business logic.
> - In Java 9, the module system pushed me to think more about boundaries and encapsulation inside large applications.
> - With Java 11, the LTS, most of my production work started to modernize â€” better performance, 
> the new HTTP client, and cleaner APIs.
> - Moving to Java 17 was another major jump, with records, sealed classes, pattern matching and overall stability. 
> It really changed how we design DTOs, domains, and safer hierarchies.
> - And today, working with Java 21, Iâ€™m taking advantage of virtual threads from Project Loom, 
> which has been a huge improvement for concurrency in backend systems.
>
---

8. Imagine que precisamos criar um ecommerce com alta demanda. 
Esporadicamente vamos realizar campanhas televisivas que gerarÃ£o acessos elevados em determinados momentos. 
A busca de nosso ecommerce tambÃ©m serÃ¡ bastante requisitada, sendo que muitos usuÃ¡rios pesquisam pelo 
mesmo produto vÃ¡rias vezes ao dia.
Como vocÃª estruturaria este projeto visando resolver os problemas relatados? 
Lembre-se que precisamos garantir escalabilidade, resiliÃªncia e rapidez.

- For a high-demand ecommerce with traffic spikes caused by TV campaigns, I would focus on CDN, 
caching, stateless services, and distributed processing.

- First, Iâ€™d place a CDN in front of all static content and use an API Gateway with rate limiting 
and horizontal scalability through Kubernetes.

- The architecture would be microservices-based, so I can scale the components that 
actually suffer pressure â€” mainly catalog and search.

- For search, Iâ€™d use Elasticsearch / OpenSearch and put Redis in front to cache repeated queries, 
since many users search for the same products multiple times a day.

- For data, Iâ€™d keep the catalog in its own database (SQL or NoSQL) and orders in a relational database 
with read replicas to spread the load.
Heavy or external operations (payment, antifraud, emails) would be decoupled using messaging (Kafka, RabbitMQ, SQS) 
to avoid bottlenecks during peak traffic.

- To ensure resilience, Iâ€™d apply timeouts, retries, circuit breakers, DLQs, and 
graceful degradation â€” prioritizing search and checkout over secondary features during TV-campaign peaks.

- Finally, Iâ€™d make everything observable with metrics (latency, errors, throughput, lag), structured logs, 
and distributed tracing to quickly identify any bottleneck.

9. How would you implement a resilient microservices architecture using Java? <br>
   Describe the standards you would use to ensure high availability.    

Every system fails. Itâ€™s something inevitable!<br>
I design microservices to fail gracefully. <br>
Using Java with Resilience4j!<br>
- I apply circuit breakers, retries, bulkheads, timeouts and fallbacks for each outbound call. 
- I keep services stateless, idempotent, and event-driven. 
- Data uses multi-AZ replicas and the Outbox pattern for consistency. 
- Kubernetes ensures health checks, autoscaling, and safe deployments through blue/green or canary rollout. 
- Observability is built in with metrics, logs, and distributed tracing. 

- The combination of these patterns delivers a highly available and fault-tolerant architecture.

---

10. Em um sistema de microserviÃ§os, como vocÃª lidaria com transaÃ§Ãµes distribuÃ­das que envolvem mÃºltiplos serviÃ§os 
e bases de dados?
In microservices, I avoid classic distributed transactions like 2PC (which creates a single point of failure) 
because they donâ€™t scale and create strong coupling between services.<br>
Instead, I rely on local transactions inside each service and coordinate the overall flow using events 
and compensations, following the Saga pattern.

I usually apply Sagas in two ways:

- Choreography: each service performs its local transaction and publishes an event; the next services react to that event. If something fails, an error event triggers the compensating actions.

- Orchestration: a central orchestrator calls each service in sequence and triggers compensations when needed.

To make this reliable, I ensure:
- Idempotency, so a service can process the same event multiple times without breaking the state.
- The Outbox Pattern, to avoid losing events between the database and the message broker.
- Retries and DLQs, to handle temporary and permanent failures.
- Observability, using correlationId to trace the entire â€œtransactionâ€ across services.

This way, I maintain consistency, low coupling, and resilience across the systemâ€”without relying 
on heavy distributed transactions.
---

11. How would you approach implementing a feature that requires high performance and needs to process large volumes 
of data in real time?

A solution needs to be available, scalable, performant, and resilient.

- performance: So the first step is understanding what â€œreal-time high performanceâ€ actually means in that context: <br>
the acceptable latency, the data volume per second, the expected SLAs, and the tolerable error rate.

- async: After that, I would design an event-driven architecture to avoid the system getting stuck on slow 
or synchronous operations. <br>
Iâ€™d use something like Kafka to ingest and partition the data, allowing multiple consumers to process 
everything in parallel and scale horizontally as the load increases.

- code: In the code itself, Iâ€™d focus on fast, asynchronous processing: avoiding blocking operations, 
using batching when it makes sense, and relying on caching (like Redis) for frequently accessed data. <br>
The idea is to keep the critical path as light as possible â€” without unnecessary remote calls 
that slow down the response.

- observability: To ensure real performance, Iâ€™d add observability from the start: latency metrics, throughput, queue size, 
CPU and memory usage, and error rate. With these metrics, Iâ€™d run load and stress tests to tune thread counts, 
batch sizes, partitioning strategy, and the number of instances.

- scalable: Finally, Iâ€™d make sure the solution can scale horizontally in an elastic environment like Kubernetes, 
and Iâ€™d implement backpressure, retry mechanisms, and a DLQ, so the system keeps running smoothly 
even during unexpected spikes.

12. Na sua experiÃªncia com Java, quais os trade-offs entre utilizar um ORM como Hibernate/JPA e JDBC puro? 
Cite quais cenÃ¡rios vocÃª recomendaria cada abordagem, considerando aspectos como performance, produtividade e manutenibilidade.

13. Descreva como vocÃª configuraria um aplicativo Spring Boot para um ambiente de produÃ§Ã£o de alta disponibilidade.
Cite quais recursos especÃ­ficos do Spring Boot (como profiles, externalized configuration, actuators) vocÃª utilizaria e
como implementaria mÃ©tricas personalizadas.

14. Descreva sua experiÃªncia na identificaÃ§Ã£o e resoluÃ§Ã£o de problemas em sistemas concorrentes, 
como deadlocks, race conditions e contenÃ§Ã£o de recursos.

15. Como vocÃª implementaria feature flags em uma aplicaÃ§Ã£o Java para permitir lanÃ§amentos graduais?<br>
A feature flag solves the problem of releasing a feature without having to bet 100% on it from day one.<br>
With feature flags, I can roll out the feature gradually, test it with smaller user groups, compare behavior, <br>
and if something goes wrong, I can turn it off within seconds â€” without any redeploy.
There are multiple ways to implement this, depending on the context and the requirements.

16. Quais estratÃ©gias vocÃª utiliza para garantir a qualidade do cÃ³digo? 
Como vocÃª implementaria uma pipeline de CI/CD com Jenkins que inclua testes e anÃ¡lise de Sonar?
Eu costumo pensar em qualidade de cÃ³digo em trÃªs nÃ­veis: como eu escrevo, como o time valida e como o pipeline protege a base de cÃ³digo.

17. Descreva uma situaÃ§Ã£o em que vocÃª precisou refatorar um cÃ³digo legado para melhorar sua manutenibilidade.

18. Que estratÃ©gias vocÃª usa para mentorar desenvolvedores mais junior?
    He is thorough when reviewing pull requests



19. VocÃª foi designado para criar uma API RESTful para gerenciamento de usuÃ¡rios em um sistema.<br>
      A API deve permitir operaÃ§Ãµes de criaÃ§Ã£o, leitura, atualizaÃ§Ã£o e exclusÃ£o de usuÃ¡rios.<br>
      Quais boas prÃ¡ticas vocÃª adotaria para garantir que essa API siga os princÃ­pios RESTful?<br>
      Como vocÃª estruturaria os endpoints e utilizaria os mÃ©todos HTTP adequadamente?<br>
      Cite tambÃ©m como lidaria com versionamento, autenticaÃ§Ã£o, autorizaÃ§Ã£o, cÃ³digos de status HTTP e tratamento de erros.

## 20. Como vocÃª estrutura seus testes unitÃ¡rios em projetos Java? Quais boas prÃ¡ticas vocÃª segue para garantir que os testes sejam confiÃ¡veis, legÃ­veis e de fÃ¡cil manutenÃ§Ã£o? Pode citar ferramentas que costuma utilizar e como vocÃª lida com mocks e dependÃªncias externas?
**Estrutura:** Given-When-Then, 1 assert principal por teste, nomes claros.
**Boas prÃ¡ticas:** isolamento de dependÃªncias, evitar mocks desnecessÃ¡rios, manter testes rÃ¡pidos.
**Ferramentas:** JUnit 5, Mockito, Testcontainers, WireMock.
**DependÃªncias externas:** mocks/stubs ou containers temporÃ¡rios para evitar acoplamento a serviÃ§os reais.

---
 

>
<br> 
âœ… Neutral/Professional:
"Once the code is written, we should test the API."Map â€“ convert from one structure to another
We map the DTO to the domain object.
âœ… More formal:
"After implementing the code, it's important to validate the API."Authenticate â€“ verify identity
The user is authenticated through Cognito.
âœ… Casual/Team discussion:
"When we're done coding, let's test the API to make sure everything works."21â€“40: Backend & Architecture
<br>Authorize â€“ give access
<br>Only admins are authorized.

Consume â€“ read from Kafka/SQS
This service consumes the event.

Produce â€“ send to Kafka/SQS
We produce a message after saving.

Handle â€“ manage an event/error
The controller handles exceptions.

Persist â€“ save permanently
We persist the data in Postgres.

Query â€“ ask the database
We query the customers table.

Cache â€“ store temporarily
We cache responses in Redis.

Expose â€“ make available
The API exposes four endpoints.

Inject â€“ provide dependency
Spring injects the repository automatically.

Implement â€“ create logic for an interface
We implemented the port adapter.

Extend â€“ inherit
The class extends the base entity.

Handle â€“ process an event/error
The service handles all retries.

Throw â€“ raise an exception
Throw an error if the result is empty.

Return â€“ send a response
The endpoint returns a JSON object.

Log â€“ record information
We log all authentication attempts.

Encrypt â€“ secure data
Encrypt the password before saving.

Deploy â€“ put into production
We deploy through GitHub Actions.

Scale â€“ increase capacity
We scaled the service to three replicas.

Monitor â€“ observe behavior
Monitor latency in Grafana.

Fail â€“ stop working
The request fails when the token expires.

41â€“60: Cloud, DevOps & Infrastructure

Provision â€“ create a resource
Terraform provisions the cluster.

Trigger â€“ start an action
A push to develop triggers the pipeline.

Rollback â€“ return to previous version
We rolled back due to errors.

Authenticate â€“ verify identity
Lambda authenticates the request.

Authorize â€“ check permissions
APIGW authorizes the user.

Deploy â€“ send to cloud
ECS deploys the new task definition.

Retry â€“ try again
Kafka retries three times.

Scale â€“ adjust resources
K8s scales according to CPU usage.

Containerize â€“ package into Docker
We containerized the application.

Route â€“ forward traffic
The ingress routes the request to service A.

Expose â€“ open a port
The deployment exposes port 8080.

Manage â€“ control resources
We manage secrets with Vault.

Rotate â€“ replace periodically
We rotate the credentials weekly.

Observe â€“ visualize metrics
Observe memory usage closely.

Store â€“ keep data
S3 stores all uploaded files.

Sync â€“ keep aligned
The DB syncs with the legacy system.

Failover â€“ switch to backup
RDS failed over automatically.

Backup â€“ save for recovery
We back up the table daily.

Recover â€“ restore after failure
The service recovered after restart.

Alert â€“ notify
Prometheus alerts when latency increases.

61â€“80: Collaboration & Meetings

Discuss â€“ talk about
Letâ€™s discuss this in the refinement.

Align â€“ reach agreement
We need to align with the PO.

Schedule â€“ plan a time
Schedule a meeting with the team.

Share â€“ provide information
Share the logs, please.

Present â€“ show something
Iâ€™ll present the architecture proposal.

Confirm â€“ validate information
Can you confirm the requirements?

Request â€“ ask formally
We requested a new SQS queue.

Report â€“ communicate status
I reported the issue to SRE.

Deliver â€“ complete a task
We deliver the feature this sprint.

Assess â€“ evaluate
We assessed the design trade-offs.

Estimate â€“ guess effort
We estimated eight story points.

Prioritize â€“ define order
Letâ€™s prioritize bugs first.

Plan â€“ organize
We plan the next iteration tomorrow.

Track â€“ follow progress
Track the task in Jira.

Lead â€“ guide a team
Carlos leads the backend chapter.

Assist â€“ help
I assisted the QA team with tests.

Guide â€“ mentor
I guided the junior devs.

Explain â€“ make clear
Let me explain the sequence diagram.

Negotiate â€“ find middle ground
We negotiated the API contract.

Collaborate â€“ work together
We collaborate across squads.

81â€“100: Thinking, Problem Solving & Quality

Analyze â€“ understand deeply
We analyzed the logs.

Investigate â€“ search for root cause
SRE is investigating the incident.

Identify â€“ find a problem
We identified a memory leak.

Evaluate â€“ judge a solution
Evaluate if this approach is safe.

Predict â€“ estimate future behavior
We predict high load on Black Friday.

Design â€“ architect something
We designed a hexagonal structure.

Architect â€“ plan high-level structure
He architected the entire platform.

Prototype â€“ create initial version
We prototyped the feature.

Test â€“ verify correctness
We test all edge cases.

Measure â€“ quantify
Measure the response time.

Compare â€“ analyze differences
Compare JSON before and after mapping.

Estimate â€“ calculate effort
Estimate the complexity honestly.

Detect â€“ find problems
We detect anomalies with Prometheus.

Prevent â€“ avoid issues
We prevent downtime with autoscaling.

Document â€“ explain in writing
Document the API request flow.

Standardize â€“ unify approach
We standardized the logging pattern.

Automate â€“ remove manual steps
We automated deployments with CI/CD.

Monitor â€“ observe behavior
Monitor Apdex after the fix.

Warn â€“ notify users
The system warns when the token expires.

Adapt â€“ adjust to context
We adapted the strategy for PCI.

------------------------
verbos mais usados

implement  
develop  
code  
refactor  
test  
deploy  
debug  
build  
design  
integrate  
document  
validate  
execute  
return  
fetch  
handle  
parse  
persist  
map  
convert  
expose  
consume  
register  
configure  
synchronize  
decouple  
encapsulate  
inject  
scale  
monitor  
analyze  
identify  
compare  
evaluate  
decide  
calculate  
determine  
estimate  
optimize  
review  
discuss  
align  
share  
update  
mention  
suggest  
clarify  
explain  
point out  
agree  
support  
help  
collaborate  
participate  
join  
contribute  
assign  
delegate  
attend  
coordinate  
plan  
prioritize  
estimate  
deliver  
define  
create  
schedule  
track  
complete  
review  
provision  
automate  
containerize  
orchestrate  
scale  
tune  
monitor  
log  
restart  
describe  
explain  
summarize  
highlight  
share  
demonstrate  
mention  
justify  
recall  
emphasize  
catch  
throw  
fail  
retry  
warn  
log  
alert  
crash  
fix  
recover
 
------------------------------------
falsos cognatos 
â­ Eventually (no fim das contas / finalmente)
Eventually, we fixed the bug in production.
Eventually, the legacy service will be replaced.
After hours of debugging, we eventually found the root cause.

â­ Actually (na verdade)
Actually, the issue wasnâ€™t in our API â€” it was in the provider.
Actually, we donâ€™t need a refactor; just a config change.
I thought it was a database problem, but actually it was a caching issue.

â­ Atualmente (in English = "currently", "nowadays")
Atualmente, estamos usando Java 21 no projeto.
Atualmente, o serviÃ§o roda no cluster de QA.
Atualmente, temos trÃªs squads trabalhando na mesma feature.

â­ Eventualmente (in English = "occasionally" / "at some point")
Eventualmente, vamos precisar migrar esse serviÃ§o para Kubernetes.
Eventualmente, algum request vai falhar â€” precisamos tratar os erros.
Eventualmente, teremos que revisar a arquitetura desse mÃ³dulo.

ğŸ”¥ Resumo para memorizar
Eventually = finalmente / no fim das contas.
Actually = na verdade.
Atualmente = currently / nowadays.
Eventualmente = occasionally / at some point.
------------------------------------

Lista de Verbos â€” Falsos Cognatos em InglÃªs
â­ 1. Pretend
TI:
Donâ€™t pretend the system is stable; the metrics show otherwise.
We can pretend the API is down to test our fallback.
Java Backend:
3. In the unit test, we pretend the repository returns an empty list.
4. Donâ€™t pretend the JVM memory leak will fix itself.

â­ 2. Intend
TI:
We intend to migrate everything to Kubernetes next quarter.
I intend to refactor this module before the next release.
Java Backend:
3. I intend to remove the synchronous call inside this loop.
4. The team intends to rewrite this service using Spring Boot 3.

â­ 3. Support
TI:
We support multiple authentication methods in this platform.
The tool doesnâ€™t support multi-region deployments yet.
Java Backend:
3. Our microservice now supports async processing with CompletableFuture.
4. The API supports pagination through query parameters.

â­ 4. Discuss
TI:
We need to discuss the security implications of this feature.
Letâ€™s discuss how this change affects the architecture.
Java Backend:
3. We should discuss whether to use Feign or WebClient.
4. Letâ€™s discuss a better structure for the DTOs.

â­ 5. Realize
TI:
I didnâ€™t realize the pipeline was failing since yesterday.
We realized the alert wasnâ€™t configured correctly.
Java Backend:
3. I realized the mapper was dropping fields silently.
4. We realized the JPA entity was not matching the database schema.

â­ 6. Attend
TI:
I canâ€™t attend the meeting; Iâ€™m reviewing a production incident.
She attended the architecture workshop yesterday.
Java Backend:
3. I attended the Spring Boot 3 migration training.
4. He attended the review session for the new API contract.

â­ 7. Assist
TI:
Iâ€™ll assist you with the CI configuration.
She assisted the team during the outage.
Java Backend:
3. I assisted my peer with debugging the Kafka consumer.
4. He assisted in rewriting the authentication filter.

â­ 8. Compromise
TI:
We may need to compromise on the delivery timeline.
The teams compromised on a shared approach to logging.
Java Backend:
3. We compromised by using a shared DTO instead of rewriting everything.
4. They compromised on using Redis rather than an in-memory cache.

â­ 9. Resume
TI:
Letâ€™s resume after the deploy is complete.
Weâ€™ll resume the discussion tomorrow.
Java Backend:
3. We can resume testing after fixing the failing controller.
4. Letâ€™s resume coding once the integration tests pass.

â­ 10. Notice
TI:
Did you notice the CPU spike in the dashboard?
I noticed the logs were duplicated.
Java Backend:
3. I noticed the service wasnâ€™t releasing database connections.
4. She noticed the Kafka offsets werenâ€™t moving forward.

â­ 11. Ignore
TI:
Donâ€™t ignore these alerts; theyâ€™re critical.
The system should ignore invalid requests.
Java Backend:
3. We canâ€™t ignore null fields in this DTO.
4. The validator shouldnâ€™t ignore empty strings.

â­ 12. Injure
(Not used literally in TI, but still usable figurativamente.)
TI:
That outage really â€œinjuredâ€ our SLA for the month.
A bad release can injure the teamâ€™s reputation.
Java Backend:
3. Poor error handling injured performance in production.
4. That huge SQL query injured the serviceâ€™s response time.

â­ 13. Introduce
TI:
We plan to introduce a new logging standard.
The new release introduces breaking changes.
Java Backend:
3. The PR introduces a new controller for payments.
4. The update introduces a retry mechanism for the API call.

â­ 14. Insert
TI:
The system wonâ€™t let us insert this record.
You need admin rights to insert data manually.
Java Backend:
3. JPA will insert the entity automatically on save.
4. The service inserts metadata before publishing to Kafka.

â­ 15. Push
TI:
Push the changes to GitHub when youâ€™re done.
We need to push a new version to the registry.
Java Backend:
3. The pipeline pushes the Docker image after the tests pass.
4. The service pushes notifications to the message broker.

â­ 16. Pull
TI:
Pull the latest version before building.
The system will pull configurations dynamically.
Java Backend:
3. The API pulls data from three different services.
4. The consumer pulls messages from the topic every second.

â­ 17. Prevent
prevent = impedir que algo aconteÃ§a
avoid = evitar / tentar nÃ£o fazer

TI:
We need to prevent this issue from happening again.
The firewall prevents external access.
Java Backend:
3. Validation prevents invalid payloads from reaching the service.
4. Retry logic prevents temporary failures from breaking the flow.

â­ 18. Provide
TI:
The platform provides real-time monitoring.
They provide full documentation for the API.
Java Backend:
3. The adapter provides the implementation for the port.
4. This class provides utility methods for mapping responses.

â­ 19. Design
TI:
We need to design a more scalable solution.
The team will design the integration flow.
Java Backend:
3. He designed the domain model following hexagonal principles.
4. We designed a new API contract for the mobile team.

â­ 20. Suggest
TI:
I suggest using feature flags for this rollout.
They suggested revisiting the architecture.
Java Backend:
3. I suggest adding tests for the mapper layer.
4. She suggested using WebClient instead of RestTemplate.

â­ 21. Execute
TI:
The pipeline will execute all checks automatically.
The script executes the deployment steps.
Java Backend:
3. The service executes a scheduled task every hour.
4. JPA executes the query lazily.

â­ 22. Fabricate
TI:
We can fabricate test data for staging.
The tool fabricates logs for simulation.
Java Backend:
3. The test fabricates a fake HTTP response.
4. We fabricated a mock event for the Kafka topic.

â­ 23. Convict
(Figurativo, mais raro, mas incluÃ­do.)
TI:
The audit logs can convict a failing component.
Monitoring can convict the root cause quickly.
Java Backend:
3. The trace IDs can convict which microservice failed first.
4. A failing unit test can convict the broken module.

â­ 24. Record
TI:
The system records all user actions.
We record metrics during load tests.
Java Backend:
3. The interceptor records execution time.
4. The listener records every message processed.

â­ 25. Advertise
TI:
The platform will advertise this new feature next week.
We donâ€™t advertise beta tools internally.
Java Backend:
3. The service advertises its endpoints through Swagger.
4. Eureka advertises available microservices.

â­ 26. Abuse
TI:
Donâ€™t abuse this API; it has strict rate limits.
Users sometimes abuse the free tier.
Java Backend:
3. The code abuses reflection and becomes hard to maintain.
4. Donâ€™t abuse static methods; they hurt testability.

â­ 27. Apply
TI:
Apply the configuration changes and restart.
You need to apply for access to this environment.
Java Backend:
3. The validator applies the business rules.
4. The filter applies the authentication checks.

â­ 28. Comprehend
TI:
Itâ€™s hard to comprehend why this bug only happens in QA.
The system behavior is difficult to comprehend without logs.
Java Backend:
3. He couldnâ€™t comprehend why the mapper was failing silently.
4. Itâ€™s hard to comprehend the flow without reading the service class.

â­ 29. Conserve
TI:
We should conserve resources in this cluster.
The design conserves bandwidth in poor networks.
Java Backend:
3. The cache helps conserve database connections.
4. The rate limiter conserves CPU under heavy load.

â­ 30. Provide (jÃ¡ listado, mas mantendo a lista original Ã  risca; se quiser troco por outro)
(Se quiser posso substituir por outro verbo falso cognato real, como "deceive", "remark", etc.)
TI:
They provide full monitoring capabilities.
We provide access only through VPN.
Java Backend:
3. The controller provides two GET endpoints.
4. This adapter provides integration with the external API.

---------------------------------------------------------
â­ ExpressÃµes profissionais para evitar filler words
ğŸ”¹ Em vez de â€œuhâ€¦ / umâ€¦â€
Use pausas estratÃ©gicas, mas quando precisar falar algo:
Let me think.
Just a moment.
Give me a second.

ğŸ”¹ Em vez de â€œyou knowâ€¦â€
Use:
As you can seeâ€¦
As you know from earlierâ€¦
As we discussedâ€¦

ğŸ”¹ Em vez de â€œlikeâ€¦â€ (quando usado como vÃ­cio)
Use:
For exampleâ€¦
Such asâ€¦
In this caseâ€¦

ğŸ”¹ Em vez de â€œsoâ€¦â€ no comeÃ§o de frase
Use:
Wellâ€¦ (mais natural)
Hereâ€™s the pointâ€¦
To summarizeâ€¦
The thing isâ€¦

ğŸ”¹ Em vez de â€œI meanâ€¦â€
Use:
What Iâ€™m trying to say isâ€¦
Let me clarifyâ€¦
In other wordsâ€¦

ğŸ”¹ Em vez de â€œbasicallyâ€¦â€
Use:
Essentiallyâ€¦
In simple termsâ€¦
The main idea isâ€¦

ğŸ”¹ Em vez de â€œright?â€ (para confirmar tudo o tempo inteiro)
Use:
Does that make sense?
Are we aligned?
Is that clear so far?

ğŸ”¹ Em vez de â€œokayâ€¦ soâ€¦â€
Use:
Moving onâ€¦
Next pointâ€¦
Letâ€™s continueâ€¦

ğŸ”¹ Em vez de â€œuhh yeahâ€¦â€ para ganhar tempo
Use:
Let me check.
Let me think for a moment.
Good question â€” hereâ€™s the answer.


ğŸ”¥ 1. Para ganhar tempo antes de responder
(em vez de: uh / um / ah / uhhh yeahâ€¦)
Let me think for a second.
Just a moment, Iâ€™m checking.
Good question â€” let me see.
One second, Iâ€™m pulling the context.

ğŸ”¥ 2. Para organizar sua fala em reuniÃµes tÃ©cnicas
(em vez de: soâ€¦ / okay soâ€¦)
Hereâ€™s the situationâ€¦
Hereâ€™s what we foundâ€¦
Letâ€™s walk through this.
Moving on to the next pointâ€¦
From a backend perspectiveâ€¦

ğŸ”¥ 3. Para explicar melhor uma decisÃ£o tÃ©cnica
(em vez de: I meanâ€¦)
What Iâ€™m trying to say isâ€¦
Let me clarify the reasoning behind this.
In other wordsâ€¦
To put it simplyâ€¦

ğŸ”¥ 4. Para citar exemplos de forma profissional
(em vez de: likeâ€¦ likeâ€¦)
For exampleâ€¦
Such asâ€¦
In this caseâ€¦
One good example isâ€¦

ğŸ”¥ 5. Para evitar â€œyou knowâ€¦â€
(melhora a postura em reuniÃµes)
As you can see from the logsâ€¦
As we discussed earlierâ€¦
As the metrics showâ€¦
From what we observedâ€¦

ğŸ”¥ 6. Para alinhar expectativas sem parecer inseguro
(em vez de: right?)
Does that make sense?
Are we aligned on this?
Is everyone okay with this approach?
Should we validate this together?

ğŸ”¥ 7. Para encerrar uma explicaÃ§Ã£o
(em vez do famoso â€œbasicallyâ€¦â€)
Essentiallyâ€¦
The key point isâ€¦
Long story shortâ€¦
The bottom line isâ€¦

ğŸ”¥ 8. Para falar sobre problemas tÃ©cnicos
(e evitar hesitaÃ§Ã£o)
Hereâ€™s whatâ€™s causing the issueâ€¦
Hereâ€™s the root causeâ€¦
This is where the service breaksâ€¦
This part is failing due toâ€¦

ğŸ”¥ 9. Para pedir algo ao time
(fortalece lideranÃ§a)
Can someone double-check this?
Letâ€™s validate this scenario.
We should review the logs together.
Please confirm this on your side.

ğŸ”¥ 10. Para iniciar uma opiniÃ£o tÃ©cnica sem parecer agressivo
(evita â€œI thinkâ€¦ I thinkâ€¦â€ repetitivo)
From my perspectiveâ€¦
Looking at the architectureâ€¦
Based on the logsâ€¦
Considering our constraintsâ€¦
From a backend standpointâ€¦


---------------------------------------------------------
praticando HAVE

â­ 1. HAVE = ter (posse / quantidade)
No dia a dia de TI
I have a meeting in five minutes.
We have a production incident.
Do you have access to this dashboard?
We have a blocker on this task.
No contexto de backend Java
We have a NullPointerException in the logs.
I have two endpoints to finish today.
Do we have a timeout on the external API?
We have a dependency issue in Maven.

â­ 2. HAVE = experienciar / passar por algo
No dia a dia de TI
We had a slow response time earlier.
I had trouble connecting to VPN today.
Weâ€™re having issues with the pipeline.
I had a problem with my permissions.
Backend Java
We had a failure in the Kafka consumer.
The service had a memory spike.
Iâ€™m having trouble with this JPA mapping.
We had an inconsistent response in QA.

â­ 3. HAVE TO = ter que (obrigaÃ§Ã£o)
TI geral
I have to check the logs.
We have to update the documentation.
Do we have to sync with the mobile team?
We have to fix this before deployment.
Java backend
I have to refactor this class.
We have to validate the DTO properly.
I have to rewrite this mapper.
We have to increase the timeout.

â­ 4. HAVE BEEN + ING = aÃ§Ã£o contÃ­nua (tem estado / tem feito)
(muito usado em daily meetings)
TI geral
Iâ€™ve been working on the integration tests.
Weâ€™ve been investigating the latency issue.
Iâ€™ve been reviewing the architecture proposal.
Weâ€™ve been debugging the incident since morning.
Java backend
Iâ€™ve been fixing the Spring configuration.
Weâ€™ve been improving the error handling.
Iâ€™ve been testing the Kafka flow.
Weâ€™ve been optimizing the database queries.

â­ 5. HAVE + PARTICÃPIO = jÃ¡ fez / jÃ¡ aconteceu
TI geral
Iâ€™ve already checked the logs.
Have you reviewed the PR?
Weâ€™ve finished the deployment.
Weâ€™ve confirmed the root cause.
Java backend
Iâ€™ve tested the endpoint.
Have you run the unit tests?
Weâ€™ve implemented the retry logic.
Iâ€™ve documented the API contract.

-------------------------------
 

praticando termos de tecnologia em inglÃªs
## Glossary of Common Tech Terms in English
> Backend Development
<br> Software Architecture
<br> Microservices
<br> Monolithic Architecture
<br> RESTful APIs
<br> Asynchronous Communication
<br> Event-Driven Architecture
<br> Cloud Computing
<br> Containerization
<br> Orchestration
<br> Continuous Integration (CI)
<br> Continuous Deployment (CD)
<br> DevOps
<br> Observability
<br> Scalability
<br> Resilience
<br> Load Balancing
<br> Fault Tolerance
<br> Domain-Driven Design (DDD)
<br> Test-Driven Development (TDD)
<br> Behavior-Driven Development (BDD)
<br> Version Control
<br> Dependency Management
<br> Code Review
<br> Agile Methodologies
<br> Scrum
<br> Kanban
<br> Software Development Life Cycle (SDLC)
<br> Infrastructure as Code (IaC)
<br> Service Mesh
<br> API Gateway
<br> Message Broker
<br> Data Serialization
<br> Authentication and Authorization
<br> Encryption
<br> Performance Optimization
<br> Refactoring
<br> Legacy Systems
<br> Technical Debt
<br> Codebase
<br> Build Automation
<br> Unit Testing
<br> Integration Testing
<br> Load Testing
<br> Mocking
<br> Logging
<br> Tracing
<br> Metrics
<br> Circuit Breaker
<br> Retry Mechanism
<br> Bulkhead Pattern
<br> Idempotency
<br> Ubiquitous Language
<br> Bounded Context
<br> Aggregate
<br> Factory Pattern
<br> Singleton Pattern
<br> Builder Pattern
<br> Adapter Pattern
<br> Facade Pattern
<br> Strategy Pattern
<br> Chain of Responsibility Pattern
<br> Protobuf (Protocol Buffers)
<br> gRPC
<br> OAuth2
<br> JWT (JSON Web Token)
<br> Kubernetes (K8s)
<br> Docker
<br> Jenkins
<br> Maven
<br> Gradle
<br> Spring Boot
<br> Spring Cloud
<br> Hibernate
<br> Kafka
<br> RabbitMQ
<br> PostgreSQL
<br> Oracle Database
<br> MongoDB
<br> DynamoDB
<br> Prometheus
<br> Grafana
<br> OpenTelemetry
<br> Splunk
<br> Jaeger
<br> AWS (Amazon Web Services)
<br> S3 (Simple Storage Service)
<br> SQS (Simple Queue Service)
<br> ECR (Elastic Container Registry)
<br> FaaS (Function as a Service)
<br> BaaS (Backend as a Service)
<br> CI/CD Pipelines
<br> Blue-Green Deployment
<br> Rollout Deployment
<br> Semantic Commit Messages
<br> Codebase
<br> system reliable

frases comuns e afirmativar em entrevistas tÃ©cnicas de desenvolvedor backend com enfase em java em ingles
## Common Phrases for Backend Developer Interviews (Java Focus)
> I have extensive experience in backend development using Java and Kotlin.
<br> I am proficient in building RESTful APIs with Spring Boot.
<br> I have worked on microservices architecture and understand its benefits and challenges.
<br> I am familiar with asynchronous communication using Kafka and RabbitMQ.
<br> I have experience with cloud platforms, particularly AWS.
<br> I am skilled in containerization with Docker and orchestration using Kubernetes.
<br> I follow best practices in software architecture, including DDD and Clean Architecture.
<br> I am comfortable with CI/CD pipelines and have used Jenkins for automation.
<br> I prioritize code quality and maintainability through code reviews and testing.
<br> I have a strong understanding of relational databases like PostgreSQL and Oracle.
<br> I am experienced in using Hibernate and JPA for data persistence.
<br> I am familiar with observability tools such as Prometheus and Grafana.
<br> I have implemented security measures using OAuth2 and JWT.
<br> I am a strong advocate for TDD and have applied it in my projects.
<br> I am adaptable and open to learning new technologies and methodologies.
<br> I am a proactive team player and enjoy collaborating with cross-functional teams.
<br> I am committed to continuous improvement and staying updated with industry trends.
<br> I am excited about the opportunity to contribute to your team and projects.
<br> Thank you for considering my application; I look forward to the possibility of working together.

frases que posso afirmar em entrevistas tÃ©cnicas de desenvolvedor backend com Ãªnfase em java em inglÃªs
## Affirmative Phrases for Backend Developer Interviews (Java Focus)
    I am confident in my ability to design and implement scalable backend systems.
    I have a proven track record of delivering high-quality software on time.
    I am skilled at troubleshooting and resolving complex technical issues.
    I am experienced in optimizing application performance and scalability.
    I have a deep understanding of Java and its ecosystem.
    I am proficient in using Spring Boot and Spring Cloud for building microservices.
    I am knowledgeable about software design patterns and best practices.
    I am comfortable working in Agile environments and following Scrum methodologies.
    I am dedicated to writing clean, maintainable, and well-documented code.
    I am experienced in mentoring junior developers and fostering a collaborative team environment.
    I am committed to continuous learning and professional development.
    I am passionate about technology and enjoy solving challenging problems.
    I am excited about the opportunity to contribute my skills and experience to your organization.
    I am eager to take on new challenges and grow as a backend developer.
    I am confident that my skills and experience align well with the requirements of this role.

---
## Phrases to Use When You Face Difficulties in English During an Interview
    "Sorry, could you please repeat that?"
    "My English is a bit rusty â€” I havenâ€™t practiced as much lately."
    "But Iâ€™m following you."
    "Could you please clarify that point?"
    "Let me make sure I understand correctly."
    "Iâ€™m not sure I caught that. Could you explain it again?"
    "I apologize for any mistakes in my English; Iâ€™m working on improving it."
    "Thank you for your patience as I express myself in English."
    "Could you please speak a bit slower? I want to make sure I understand everything."
    "I appreciate your understanding as I navigate this conversation in English."

----------------------------------

## technicle interview

- 4 principals de POO

- hash code and equals

- garbage collection

- collections em java na profundidade

- design patterns

- spring

- injection ande dependenci injection (citando via construtor e anotations)

- spring profiles

- tests

- docker e virtual machine

- vertical and horizontal scale

- cloulds

- agile (grooming sessions)





